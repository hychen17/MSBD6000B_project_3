{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'E:\\\\ust\\\\6000B\\\\proj3\\\\Dataset_A\\\\data\\\\'\n",
    "file_path = 'E:\\\\ust\\\\6000B\\\\proj3\\\\Dataset_A\\\\'\n",
    "model_path = 'E:\\\\ust\\\\6000B\\\\proj3\\\\model\\\\'\n",
    "color = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 图片和标签的字典 {img ： label}\n",
    "img_label={}\n",
    "with open(file_path + 'train.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip('\\n')\n",
    "        img = line.split('\\t')[0]\n",
    "        label = line.split('\\t')[1]\n",
    "        img_label[img] = float(label)\n",
    "        \n",
    "img_label_val={}\n",
    "with open(file_path + 'val.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip('\\n')\n",
    "        img = line.split('\\t')[0]\n",
    "        label = line.split('\\t')[1]\n",
    "        img_label_val[img] = float(label)\n",
    "        \n",
    "img_label_test={}\n",
    "with open(file_path + 'test.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.strip('\\n')\n",
    "        img_label_test[line] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading training data\n",
      "finish loading validation data\n",
      "finish loading testing data\n"
     ]
    }
   ],
   "source": [
    "sample_img = []\n",
    "for name in list(img_label.keys())[:]:\n",
    "#for name in ['22614074','22614097','22614127','22614150']:\n",
    "    for img in os.listdir(data_path):\n",
    "        if img.startswith(name):\n",
    "            sample_img.append([name,cv.imread(data_path+img,color)])\n",
    "print('finish loading training data')\n",
    "\n",
    "sample_img_val = []\n",
    "for name in list(img_label_val.keys())[:]:\n",
    "#for name in ['24055024','24054997','24065270','20587080']:\n",
    "    for img in os.listdir(data_path):\n",
    "        if img.startswith(name):\n",
    "            sample_img_val.append([name,cv.imread(data_path+img,color)])\n",
    "print('finish loading validation data')\n",
    "            \n",
    "sample_img_test = []\n",
    "for name in list(img_label_test.keys())[:]:\n",
    "#for name in ['24055024','24054997','24065270','20587080']:\n",
    "    for img in os.listdir(data_path):\n",
    "        if img.startswith(name):\n",
    "            sample_img_test.append([name,cv.imread(data_path+img,color)])\n",
    "print('finish loading testing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish filtering training data\n",
      "finish filtering validation data\n",
      "finish filtering testing data\n"
     ]
    }
   ],
   "source": [
    "# 垂直对乳房轮廓画条切线，把不包括乳房的部分去除\n",
    "filtered_img = []\n",
    "for img in sample_img:\n",
    "    col_2_keep = []\n",
    "    col_index = 0\n",
    "    for img_col in img[1].T:\n",
    "        if (img_col>0).any():\n",
    "            col_2_keep.append(col_index)\n",
    "        col_index += 1\n",
    "    filtered_img.append([img[0],img[1].T[col_2_keep].T])\n",
    "print('finish filtering training data')\n",
    "\n",
    "    \n",
    "filtered_img_val = []\n",
    "for img in sample_img_val:\n",
    "    col_2_keep = []\n",
    "    col_index = 0\n",
    "    for img_col in img[1].T:\n",
    "        if (img_col>0).any():\n",
    "            col_2_keep.append(col_index)\n",
    "        col_index += 1\n",
    "    filtered_img_val.append([img[0],img[1].T[col_2_keep].T])\n",
    "print('finish filtering validation data')\n",
    "\n",
    "filtered_img_test = []\n",
    "for img in sample_img_test:\n",
    "    col_2_keep = []\n",
    "    col_index = 0\n",
    "    for img_col in img[1].T:\n",
    "        if (img_col>0).any():\n",
    "            col_2_keep.append(col_index)\n",
    "        col_index += 1\n",
    "    filtered_img_test.append([img[0],img[1].T[col_2_keep].T])\n",
    "print('finish filtering testing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish retrieving patches of training data\n",
      "finish retrieving patches of validation data\n",
      "finish retrieving patches of testing data\n"
     ]
    }
   ],
   "source": [
    "# 分patch\n",
    "patches = []\n",
    "patch_w = 250\n",
    "patch_h = 250\n",
    "for img in filtered_img:\n",
    "    \n",
    "    # 图片（丢掉黑色部分）的长宽\n",
    "    filtered_img_h = img[1].shape[0]\n",
    "    filtered_img_w = img[1].shape[1]\n",
    "    \n",
    "    patch_top_left_corner_y = 0\n",
    "    # 一行一行往下扫\n",
    "    while (patch_top_left_corner_y + patch_h) < filtered_img_h:\n",
    "        \n",
    "        # 一列一列往右扫\n",
    "        patch_top_left_corner_x = 0\n",
    "        while (patch_top_left_corner_x + patch_w) < filtered_img_w:\n",
    "            patch = img[1][patch_top_left_corner_y : patch_top_left_corner_y + patch_h,\n",
    "                           patch_top_left_corner_x : patch_top_left_corner_x + patch_w ]\n",
    "            \n",
    "            if (patch>0).all():\n",
    "                # [bag, label, 坐标[左上角行数，左上角列数]，patch的每个像素]\n",
    "                # normalize patch\n",
    "                #patch = (patch - patch.min())/ (patch.max() -  patch.min())\n",
    "                patches.append([img[0],img_label[img[0]],patch.reshape((patch_h,patch_w,1))])\n",
    "            \n",
    "            patch_top_left_corner_x += patch_w\n",
    "        patch_top_left_corner_y += patch_h\n",
    "\n",
    "print('finish retrieving patches of training data')\n",
    "patches_val = []\n",
    "for img in filtered_img_val:\n",
    "    \n",
    "    # 图片（丢掉黑色部分）的长宽\n",
    "    filtered_img_h = img[1].shape[0]\n",
    "    filtered_img_w = img[1].shape[1]\n",
    "    \n",
    "    patch_top_left_corner_y = 0\n",
    "    # 一行一行往下扫\n",
    "    while (patch_top_left_corner_y + patch_h) < filtered_img_h:\n",
    "        \n",
    "        # 一列一列往右扫\n",
    "        patch_top_left_corner_x = 0\n",
    "        while (patch_top_left_corner_x + patch_w) < filtered_img_w:\n",
    "            patch = img[1][patch_top_left_corner_y : patch_top_left_corner_y + patch_h,\n",
    "                           patch_top_left_corner_x : patch_top_left_corner_x + patch_w ]\n",
    "            \n",
    "            if (patch>0).all():\n",
    "                # [bag, label, 坐标[左上角行数，左上角列数]，patch的每个像素]\n",
    "                #patch = (patch - patch.min())/ (patch.max() -  patch.min())\n",
    "                patches_val.append([img[0],img_label[img[0]],patch.reshape((patch_h,patch_w,1))])\n",
    "            \n",
    "            patch_top_left_corner_x += patch_w\n",
    "        patch_top_left_corner_y += patch_h\n",
    "\n",
    "print('finish retrieving patches of validation data')\n",
    "patches_test = []\n",
    "for img in filtered_img_test:\n",
    "    \n",
    "    # 图片（丢掉黑色部分）的长宽\n",
    "    filtered_img_h = img[1].shape[0]\n",
    "    filtered_img_w = img[1].shape[1]\n",
    "    \n",
    "    patch_top_left_corner_y = 0\n",
    "    # 一行一行往下扫\n",
    "    while (patch_top_left_corner_y + patch_h) < filtered_img_h:\n",
    "        \n",
    "        # 一列一列往右扫\n",
    "        patch_top_left_corner_x = 0\n",
    "        while (patch_top_left_corner_x + patch_w) < filtered_img_w:\n",
    "            patch = img[1][patch_top_left_corner_y : patch_top_left_corner_y + patch_h,\n",
    "                           patch_top_left_corner_x : patch_top_left_corner_x + patch_w ]\n",
    "            \n",
    "            if (patch>0).all():\n",
    "                # [bag, label, 坐标[左上角行数，左上角列数]，patch的每个像素]\n",
    "                #patch = (patch - patch.min())/ (patch.max() -  patch.min())\n",
    "                patches_test.append([img[0],img_label[img[0]],patch.reshape((patch_h,patch_w,1))])\n",
    "            \n",
    "            patch_top_left_corner_x += patch_w\n",
    "        patch_top_left_corner_y += patch_h\n",
    "        \n",
    "print('finish retrieving patches of testing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_img = []\n",
    "patches_y = []\n",
    "patches_x = []\n",
    "\n",
    "for p in patches:\n",
    "    patches_img.append(p[0])\n",
    "    patches_y.append(p[1])\n",
    "    patches_x.append(p[2])\n",
    "\n",
    "patches_img = np.array(patches_img).reshape((-1,1))\n",
    "patches_y = np.array(patches_y).reshape((-1,1))\n",
    "patches_x = np.array(patches_x)\n",
    "\n",
    "patches_img_val = []\n",
    "patches_y_val = []\n",
    "patches_x_val = []\n",
    "\n",
    "for p in patches_val:\n",
    "    patches_img_val.append(p[0])\n",
    "    patches_y_val.append(p[1])\n",
    "    patches_x_val.append(p[2])\n",
    "\n",
    "patches_img_val = np.array(patches_img_val).reshape((-1,1))\n",
    "patches_y_val = np.array(patches_y_val).reshape((-1,1))\n",
    "patches_x_val = np.array(patches_x_val)\n",
    "\n",
    "patches_img_test = []\n",
    "patches_y_test = []\n",
    "patches_x_test = []\n",
    "\n",
    "for p in patches_val:\n",
    "    patches_img_test.append(p[0])\n",
    "    patches_y_test.append(p[1])\n",
    "    patches_x_test.append(p[2])\n",
    "\n",
    "patches_img_test = np.array(patches_img_test).reshape((-1,1))\n",
    "patches_y_test = np.array(patches_y_test).reshape((-1,1))\n",
    "patches_x_test = np.array(patches_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minibatch(train_img,train_label,train_name,num_data,batch_size):\n",
    "    batches = []\n",
    "    num_of_minibatch = int(num_data/batch_size)\n",
    "    indices = np.arange(num_data)\n",
    "    np.random.shuffle(indices)\n",
    "    for i in range(num_of_minibatch):\n",
    "        ind = indices[(i*batch_size):((i+1)*batch_size)]\n",
    "        feature_batch = train_img[ind,:,:,:]\n",
    "        label_batch = train_label[ind,:]\n",
    "        name_batch = train_name[ind,:]\n",
    "        batches.append([feature_batch,label_batch,name_batch])\n",
    "        \n",
    "    return batches   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_conv1_1:  (?, 250, 250, 3)\n",
      "h_conv1_1_flat:  (?, 187500)\n",
      "y_conv_1_1:  (?, 1)\n",
      "h_conv2.1:  (154, 250, 250, 3)\n",
      "h_pool2_1:  (154, 125, 125, 3)\n",
      "h_conv2_2:  (154, 125, 125, 3)\n",
      "h_pool2_2:  (154, 63, 63, 3)\n",
      "h_pool2_2_flat:  (154, 11907)\n",
      "y_conv_2_1:  (154, 128)\n",
      "y_conv_2_2:  (154,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "importance = 0.6\n",
    "filter_w  = 10\n",
    "filter_h  = 10\n",
    "feature_map = 3\n",
    "fc_node = 128\n",
    "l_r = 0.05\n",
    "epoch = 3\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.6)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "##################################################\n",
    "# 选重要的patch\n",
    "##################################################\n",
    "x_image = tf.placeholder(tf.float32, [None,patch_w,patch_h,1])\n",
    "\n",
    "# 卷积1\n",
    "W_conv1_1 = weight_variable([filter_w, filter_h, 1, feature_map])\n",
    "b_conv1_1 = bias_variable([feature_map])\n",
    "h_conv1_1 = tf.nn.relu(conv2d(x_image, W_conv1_1) + b_conv1_1)\n",
    "print('h_conv1_1: ',str(h_conv1_1.shape))\n",
    "\n",
    "# 全连接1\n",
    "dim = int(h_conv1_1.shape[1] * h_conv1_1.shape[2] * h_conv1_1.shape[3])\n",
    "W_fc1_1 = weight_variable([dim,1])\n",
    "b_fc1_1 = bias_variable([1])\n",
    "\n",
    "h_conv1_1_flat = tf.reshape(h_conv1_1, [-1, dim])\n",
    "print('h_conv1_1_flat: ',str(h_conv1_1_flat.shape))\n",
    "y_conv_1_1 = tf.nn.sigmoid(tf.matmul(h_conv1_1_flat, W_fc1_1) + b_fc1_1)\n",
    "print('y_conv_1_1: ',str(y_conv_1_1.shape))\n",
    "\n",
    "values, indices = tf.nn.top_k(tf.reshape(y_conv_1_1,(1,-1)), k=round(batch_size*importance), sorted=True)\n",
    "indices = tf.reshape(indices,[-1])\n",
    "selected_x_image = tf.gather(x_image,indices)\n",
    "\n",
    "\n",
    "\n",
    "# # 对着label的0,1做变换，然后挑出前60%\n",
    "# y_ = tf.placeholder(tf.float32, [batch_size, 1])\n",
    "# y_conv_1_1 = tf.multiply(y_conv_1_1,y_) + (1 - y_)*(1-y_conv_1_1)\n",
    "# print('y_conv_1_1: ',str(y_conv_1_1.shape))\n",
    "\n",
    "# values, indices = tf.nn.top_k(tf.reshape(y_conv_1_1,(1,-1)), k=round(batch_size*importance), sorted=True)\n",
    "# #nn_output = round(batch_size*importance) - tf.reduce_sum(values)\n",
    "\n",
    "# indices = tf.reshape(indices,[-1])\n",
    "# print(indices.shape)\n",
    "# selected_x_image = tf.gather(x_image,indices)\n",
    "# print(selected_x_image.shape)\n",
    "\n",
    "##################################################\n",
    "# 挑出了头60%个重要的,然后把这些重要的再扔进另一个cnn里做预测\n",
    "##################################################\n",
    "\n",
    "\n",
    "# 卷积1\n",
    "W_conv2_1 = weight_variable([filter_w, filter_h, 1, feature_map])\n",
    "b_conv2_1 = bias_variable([feature_map])\n",
    "h_conv2_1 = tf.nn.relu(conv2d(selected_x_image, W_conv2_1) + b_conv2_1)\n",
    "print('h_conv2.1: ',str(h_conv2_1.shape))\n",
    "\n",
    "h_pool2_1 = max_pool_2x2(h_conv2_1)\n",
    "print('h_pool2_1: ',str(h_pool2_1.shape))\n",
    "\n",
    "# 卷积2\n",
    "W_conv2_2 = weight_variable([filter_w, filter_h, feature_map, feature_map])\n",
    "b_conv2_2 = bias_variable([feature_map])\n",
    "h_conv2_2 = tf.nn.relu(conv2d(h_pool2_1, W_conv2_2) + b_conv2_2)\n",
    "print('h_conv2_2: ',str(h_conv2_2.shape))\n",
    "\n",
    "h_pool2_2 = max_pool_2x2(h_conv2_2)\n",
    "print('h_pool2_2: ',str(h_pool2_2.shape))\n",
    "\n",
    "# 全连接1\n",
    "dim = int(h_pool2_2.shape[1] * h_pool2_2.shape[2] * h_pool2_2.shape[3])\n",
    "W_fc2_1 = weight_variable([dim,fc_node])\n",
    "b_fc2_1 = bias_variable([fc_node])\n",
    "\n",
    "h_pool2_2_flat = tf.reshape(h_pool2_2, [-1, dim])\n",
    "print('h_pool2_2_flat: ',str(h_pool2_2_flat.shape))\n",
    "y_conv_2_1 = tf.nn.relu(tf.matmul(h_pool2_2_flat, W_fc2_1) + b_fc2_1)\n",
    "print('y_conv_2_1: ',str(y_conv_2_1.shape))\n",
    "\n",
    "# 全连接2\n",
    "W_fc2_2 = weight_variable([fc_node,1])\n",
    "b_fc2_2 = bias_variable([1])\n",
    "\n",
    "reduce = tf.reshape(tf.matmul(y_conv_2_1, W_fc2_2) + b_fc2_2,[-1])\n",
    "y_conv_2_2 = tf.nn.softmax(reduce)\n",
    "print('y_conv_2_2: ',str(y_conv_2_2.shape))\n",
    "\n",
    "# 标签和被选中的标签\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "y = tf.reshape(y_,[-1])\n",
    "selected_y_ = tf.gather(y,indices)\n",
    "\n",
    "# 图片的名字和被选中的图片名字\n",
    "img_name_ = tf.placeholder(tf.float32, [None, 1])\n",
    "img_name = tf.reshape(img_name_,[-1])\n",
    "selected_img_name = tf.gather(img_name,indices)\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = selected_y_ ,logits= y_conv_2_2))\n",
    "#cross_entropy = tf.reduce_mean(tf.pow((selected_y_ - y_conv_2_2),2))\n",
    "train_step = tf.train.AdamOptimizer(l_r).minimize(cross_entropy)\n",
    "\n",
    "#correct_prediction = tf.gather(y_,indices) - y_conv_2_2\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  step:  1\n",
      "training loss:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-67dee5f8f6ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch: '\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' step: '\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training loss:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx_image\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_name_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validation loss:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "saver = tf.train.Saver()\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(epoch):\n",
    "    train_minibatches = minibatch(patches_x,patches_y,patches_img,len(patches),batch_size)\n",
    "    val_minibatches = minibatch(patches_x_val,patches_y_val,patches_img_val,len(patches_val),batch_size)\n",
    "    step = 0    \n",
    "    for b in train_minibatches:\n",
    "        step += 1\n",
    "        train_step.run(feed_dict ={x_image: b[0], y_: b[1]})\n",
    "        if step % 1 == 0 and step>0:\n",
    "            print('epoch: ' , str(e), ' step: ' , str(step))\n",
    "            print('training loss:')\n",
    "            print(sess.run(cross_entropy,feed_dict = {x_image: b[0], y_: b[1], img_name_: b[2]}))\n",
    "            print('validation loss:')\n",
    "            loss_val = 0\n",
    "            for b_val in val_minibatches:\n",
    "                loss_val += sess.run(cross_entropy,feed_dict = {x_image: b_val[0], y_: b_val[1], img_name_: b_val[2]})\n",
    "            print(loss_val/(len(patches_val)/batch_size))\n",
    "            print('prediction: ')\n",
    "            print(sess.run(y_conv_2_2,feed_dict = {x_image: b[0], y_: b[1], img_name_: b[2]}))\n",
    "            print(sess.run(y_conv_2_2,feed_dict = {x_image: b[0], y_: b[1], img_name_: b[2]}))\n",
    "            print('total time elapsed: ' + str(time.time()-start_time))\n",
    "            print('********************************************************')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: E:\\ust\\6000B\\proj3\\model\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "result,from_img = sess.run([y_conv_2_2,selected_img_name],feed_dict = {x_image: patches_x_test,img_name_: patches_img_test})\n",
    "#from_img = sess.run(selected_img_name,feed_dict = {x_image: patches_x_test})\n",
    "\n",
    "# save model\n",
    "save_path = saver.save(sess, model_path + 'model.ckpt')\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write to csv\n",
    "prediction = []\n",
    "img_name = []\n",
    "cnt = 0\n",
    "for r in result:\n",
    "    img_name.append(from_img[cnt,0])\n",
    "    p = sum(list(r))/len(list(r))\n",
    "    if p > 0.5:\n",
    "        prediction.append(p)\n",
    "    cnt += 1\n",
    "    \n",
    "with open(model_path + 'project2_20451451.csv','w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for k,v in enumerate(predition):\n",
    "        writer.writerows([img_name[k],str(v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
